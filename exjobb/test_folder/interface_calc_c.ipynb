{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio.PDB import *\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "#This is for removing Bio.python warnings\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_residue_dist(residue1, residue2,layers) :\n",
    "    \"\"\"Returns the C-alpha distance between two residues\"\"\"\n",
    "    layers_VDW=[]\n",
    "    layers_CA=[]\n",
    "    layers_HA=[]\n",
    "\n",
    "    for atom1 in residue1:\n",
    "        for atom2 in residue2:\n",
    "\n",
    "            distance=atom1-atom2    \n",
    "\n",
    "            if distance>20:#If the residues is to far from eachother there is no need to calculate the distance for the rest of the atoms\n",
    "                return (layers)\n",
    "            if distance >8:#Go to the next atom\n",
    "                continue\n",
    "            if distance<=0.5:\n",
    "                #layers_VDW.append([str(residue1.get_full_id()[3][1]) +'.'+ residue1.get_resname() +'-'+ str(residue2.get_full_id()[3][1]) +'.'+ residue2.get_resname(),atom1.get_name() +'-'+ atom2.get_name(), distance])\n",
    "                layers.setdefault('VDW', []).append([str(residue1.get_full_id()[3][1]) +'.'+ residue1.get_resname() +'-'+ str(residue2.get_full_id()[3][1]) +'.'+ residue2.get_resname(),atom1.get_name() +'-'+ atom2.get_name(), distance])\n",
    "\n",
    "                \n",
    "            if 'H' not in atom1.get_id() and 'H' not in atom2.get_id(): # DUBBELKOLLA ATT DET INTE FINNS H I ANDRA!!!!\n",
    "            #if atom1.get_id() != 'H' and atom2.get_id() != 'H':    \n",
    "                if atom1.get_name()=='CA' and atom2.get_name()=='CA' and distance<=8: #CA-CA distance\n",
    "                    #layers_CA.append([str(residue1.get_full_id()[3][1]) +'.'+ residue1.get_resname() +'-'+ str(residue2.get_full_id()[3][1]) +'.'+ residue2.get_resname(),atom1.get_name() +'-'+ atom2.get_name(), distance])\n",
    "                    layers.setdefault('CA-CA', []).append([str(residue1.get_full_id()[3][1]) +'.'+ residue1.get_resname() +'-'+ str(residue2.get_full_id()[3][1]) +'.'+ residue2.get_resname(),atom1.get_name() +'-'+ atom2.get_name(), distance])\n",
    "                if distance<=5: #Heavy atoms distance\n",
    "                    #layers_HA.append([str(residue1.get_full_id()[3][1]) +'.'+ residue1.get_resname() +'-'+ str(residue2.get_full_id()[3][1]) +'.'+ residue2.get_resname(),atom1.get_name() +'-'+ atom2.get_name(), distance])\n",
    "                    layers.setdefault('H-A', []).append([str(residue1.get_full_id()[3][1]) +'.'+ residue1.get_resname() +'-'+ str(residue2.get_full_id()[3][1]) +'.'+ residue2.get_resname(),atom1.get_name() +'-'+ atom2.get_name(), distance])\n",
    "                    layers.setdefault('dist',[]).append([atom1.get_serial_number(),atom2.get_serial_number(), distance])\n",
    "    return (layers)\n",
    "    #if layers_HA==[] and layers_VDW==[] and layers_CA==[]:\n",
    "     #   return\n",
    "    #else:\n",
    "     #   return ([layers_VDW,layers_CA,layers_HA])\n",
    "\n",
    "    print(layers_VDW,layers_CA,layers_HA)\n",
    "    return (layers_VDW,layers_CA,layers_HA)\n",
    "\n",
    "\n",
    "def calc_dist_matrix(chain_one, chain_two,layers) :\n",
    "    \"\"\"Returns a matrix of C-alpha distances between two chains\"\"\"\n",
    "\n",
    "    for row, residue_one in enumerate(chain_one) :\n",
    "        for col, residue_two in enumerate(chain_two) :\n",
    "            #contact=(calc_residue_dist(residue_one, residue_two,layers))\n",
    "            layers=calc_residue_dist(residue_one, residue_two,layers)\n",
    "                           \n",
    "\n",
    "            #print('contact',contact)\n",
    "            #if contact!=None:\n",
    "                #layers.append(contact)\n",
    "                #print(contact)\n",
    "                #print('---------------------')\n",
    "            #layers.append(contact)\n",
    "            \n",
    "    return (layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning(protein_train,protein_target):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.convolutional import Conv3D,Conv1D\n",
    "    from keras.layers import Conv3D, MaxPooling3D,Activation,Reshape,Dense,AveragePooling1D,Dropout,Flatten\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "    from keras.optimizers import Adam\n",
    "    \n",
    "    import keras.backend as K #For compile\n",
    "    \n",
    "    print('Start training')\n",
    "    seq = Sequential()\n",
    "\n",
    "    #seq.add(Conv3D(11, 3, 3, 3, activation='relu', \n",
    "                            #border_mode='valid', name='conv1',\n",
    "                            #subsample=(1, 1, 1),\n",
    "                            #dim_ordering='th', \n",
    "                            #input_shape=(11,120, 120, 120)))\n",
    "\n",
    "\n",
    "    seq.add(Conv1D(filters=128, kernel_size=(3), strides=(1), activation='relu',padding='valid', input_shape=(600,3)))\n",
    "    \n",
    "    seq.add(Conv1D(filters=128, kernel_size=(3), strides=(1), activation='relu',padding='valid', input_shape=(600,3)))\n",
    "\n",
    "    seq.add(AveragePooling1D(pool_size=2, strides=None, padding='valid'))\n",
    "    \n",
    "    seq.add(Dropout(0.25))\n",
    "    \n",
    "    seq.add(Conv1D(filters=256, kernel_size=(3), strides=(1), activation='relu',padding='valid', input_shape=(600,3)))\n",
    "    \n",
    "    seq.add(Conv1D(filters=256, kernel_size=(3), strides=(1), activation='relu',padding='valid', input_shape=(600,3)))\n",
    "\n",
    "    seq.add(AveragePooling1D(pool_size=2, strides=None, padding='valid'))\n",
    "    \n",
    "    seq.add(Dropout(0.25))\n",
    "    \n",
    "    seq.add(Flatten())\n",
    "    \n",
    "    seq.add(Dense(4096,activation='relu'))\n",
    "    seq.add(Dense(4096,activation='relu'))\n",
    "    \n",
    "    seq.add(Dense(4096,activation='tanh'))\n",
    "    seq.add(Dense(4096,activation='tanh'))\n",
    "    \n",
    "    seq.add(Dropout(0.5))\n",
    "\n",
    "    #seq.add(Activation('linear'))\n",
    "   # seq.add(Dense(256,activation='linear'))\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Activation('linear'))\n",
    "    #seq.add(Dense(128,activation='linear'))\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Activation('linear'))\n",
    "   # seq.add(Dense(1,activation='linear'))\n",
    "    \n",
    "    \n",
    "\n",
    "    seq.summary()\n",
    "    print('ready')\n",
    "    def mean_pred(y_true, y_pred):\n",
    "        return K.mean(y_pred)\n",
    "    \n",
    "    #protein_target=np.random.rand(16)\n",
    "    #protein_target=np.random.rand(16,269748)\n",
    "    #protein_train=np.random.rand(16,11,120,120,120)\n",
    "\n",
    "    adam = Adam(lr=0.0003, decay=0.01)\n",
    "    seq.compile(loss='mean_squared_error',\n",
    "            optimizer=adam,\n",
    "              metrics=['accuracy', mean_pred])\n",
    "\n",
    "    \n",
    "    seq.fit(protein_train,protein_target,\n",
    "          epochs=20,\n",
    "          batch_size=9)\n",
    "    \n",
    "    print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save or load -r\n",
      "-Loading files...\n",
      "-Files loaded\n",
      "('dist_matrix: ', (56,))\n",
      "('score: ', (56,))\n",
      "<type 'numpy.ndarray'>\n",
      "(427, 3)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.float64'>\n",
      "Start training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 598, 128)          1280      \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 596, 128)          49280     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 298, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 298, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 296, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 294, 256)          196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 147, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 147, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37632)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              154144768 \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 204,834,688\n",
      "Trainable params: 204,834,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "ready\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dropout_8 to have shape (None, 4096) but got array with shape (56, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c8cab129b5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-c8cab129b5e0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mdist_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mdeep_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e6daec34ef33>\u001b[0m in \u001b[0;36mdeep_learning\u001b[0;34m(protein_train, protein_target)\u001b[0m\n\u001b[1;32m     76\u001b[0m     seq.fit(protein_train,protein_target,\n\u001b[1;32m     77\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m           batch_size=9)\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dropout_8 to have shape (None, 4096) but got array with shape (56, 1)"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #Dir path\n",
    "    #args = sys.argv[1:]\n",
    "    pdb_dir= '/home/joakim/Downloads/models' #str(args[0]) #'D:\\Downloads\\CnM-dataset\\models'\n",
    "\n",
    "    while 'true':\n",
    "        input1=raw_input(\"Save or load \")\n",
    "        if input1.lower()=='-r':\n",
    "            args='-r'\n",
    "            break\n",
    "        elif input1.lower()=='-s':\n",
    "            args='-s'\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    if not '-r' in args:\n",
    "        df=pandas.read_excel('/home/joakim/Downloads/cross_val_sets.xls')\n",
    "        targets={}\n",
    "        for i,row in df.iterrows():\n",
    "             targets.setdefault(i, []).append(row['Targets'].split())\n",
    "\n",
    "        dir_home='/home/joakim/Downloads/CnM-dataset/MOAL_Benchmark_test/'\n",
    "        datasets={}\n",
    "\n",
    "\n",
    "        for dir in os.listdir(dir_home):\n",
    "            for key,target in targets.items():\n",
    "                if dir in str(target):\n",
    "                    datasets.setdefault(key, []).append(dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        score=[]\n",
    "        dist_matrix=[]\n",
    "        for key,protein_list in datasets.items():\n",
    "\n",
    "            for prot_counter,protein in enumerate(protein_list):\n",
    "\n",
    "\n",
    "                pdb_list=[]\n",
    "                for file in os.listdir(dir_home + protein):\n",
    "\n",
    "                    if file.endswith(\".pdb\"):\n",
    "                        pdb_list.append([dir_home + protein,file])\n",
    "\n",
    "\n",
    "\n",
    "               # pdb_list=[]\n",
    "               # for file in os.listdir(dir_home + protein):\n",
    "                   # if file.endswith(\".pdb\"):\n",
    "                        #pdb_list.append(args+'/'+file)\n",
    "                     #   pdb_list.append([dir_home + protein,file])\n",
    "\n",
    "\n",
    "                valuefile='/home/joakim/Downloads/CnM.featuresNPqDNZ'#'D:\\Downloads\\CnM.featuresNPqDNZ'\n",
    "                value_df=pandas.read_csv(valuefile,delim_whitespace=1)\n",
    "\n",
    "\n",
    "\n",
    "                for counter, filepath_pdb in enumerate(pdb_list):\n",
    "                    #print(counter)\n",
    "                    #print(pdb_list[counter][1])\n",
    "                    filename_pdb=os.path.join(pdb_list[counter][0],pdb_list[counter][1])\n",
    "                    print filename_pdb\n",
    "                    try: \n",
    "                        PDBobj = PDBParser()\n",
    "                        structure = PDBobj.get_structure(filename_pdb, filename_pdb)\n",
    "                        model = structure[0]\n",
    "                    except IOError: \n",
    "                        print('IO Error', filename_pdb)      \n",
    "                        while 'true':\n",
    "                            input1=raw_input(\"Error parsing PDB file! Continue(y/n)...\")\n",
    "                            if input1.lower()=='y':\n",
    "                                continue\n",
    "                            elif input1.lower()=='n':\n",
    "                                sys.exit()\n",
    "\n",
    "\n",
    "                    score.append(value_df.loc[((value_df['#'] == pdb_list[counter][1][:-11]),'CPscore')].values[0])\n",
    "\n",
    "                    #manager = multiprocessing.Manager()\n",
    "                    #return_dict = manager.list\n",
    "                    #jobs = []\n",
    "                    #job_count=0\n",
    "\n",
    "                    chain_used=[]\n",
    "                    layers={}\n",
    "                    layers.setdefault('VDW', []).append(['Check'])\n",
    "                    layers.setdefault('CA-CA', []).append(['Check'])\n",
    "                    layers.setdefault('H-A', []).append(['Check'])\n",
    "                    for chain1 in model:\n",
    "                        for chain2 in model:\n",
    "                            if chain1!=chain2 and chain2 not in chain_used:\n",
    "                                chain_used.append(chain1) \n",
    "                                #layers=[]\n",
    "                                layers = calc_dist_matrix(chain1, chain2,layers)\n",
    "                                #p = multiprocessing.Process(target=dist_matrix.append, args=(job_count,return_dict))\n",
    "                                #jobs.append(p)\n",
    "                                #p.start()\n",
    "                                #job_count=job_count+1\n",
    "                                #print(return_dict)\n",
    "                                #dist_matrix.append(calc_dist_matrix(chain1, chain2,layers))\n",
    "\n",
    "                                #contact_map = dist_matrix < 12.0\n",
    "\n",
    "\n",
    "                   # if 'dist_matrix' in dir():\n",
    "                    dist_matrix.append(np.array(layers['dist']))\n",
    "                        #dist_matrix=np.append(dist_matrix,layers['dist'])\n",
    "                        #dist_matrix=np.concatenate((dist_matrix, layers['dist']))\n",
    "                    #else:\n",
    "                       # dist_matrix=np.array(layers['dist'])\n",
    "                    print len(dist_matrix)\n",
    "\n",
    "        dist_matrix=np.array(dist_matrix)    \n",
    "        score=np.array(score)\n",
    "        print('dist_matrix: ', dist_matrix.shape)\n",
    "        print('score: ',score.shape)\n",
    "\n",
    "    if '-s' in args and '-r' in args:\n",
    "        print('Do not use save(-s) and read(-r) at the same time')\n",
    "        sys.exit()\n",
    "    elif '-s' in args:\n",
    "        print('-Saving files...')\n",
    "        np.savez_compressed('score', score)\n",
    "        np.savez_compressed('dist_matrix', dist_matrix)\n",
    "        #np.savez_compressed('dist_matrix', dist_matrix)\n",
    "        print('-Files saved as \"dist_matrix.npz\",\"score.npz\"')\n",
    "\n",
    "    elif '-r' in args:\n",
    "        print('-Loading files...')\n",
    "        score = np.load('score.npz')\n",
    "        dist_matrix = np.load('dist_matrix.npz')\n",
    "        \n",
    "        for key,array in score.items():\n",
    "            score=score[key]\n",
    "        for key,array in dist_matrix.items():\n",
    "            dist_matrix=dist_matrix[key]\n",
    "            \n",
    "        print('-Files loaded')\n",
    "    \n",
    "    \n",
    "    print('dist_matrix: ', dist_matrix.shape)\n",
    "    print('score: ',score.shape)\n",
    "    \n",
    "    print type(dist_matrix)\n",
    "    print dist_matrix[1].shape\n",
    "    print type(dist_matrix[1][1])\n",
    "    print type(dist_matrix[1][1][1])\n",
    "    \n",
    "    dist_matrix=[]\n",
    "    dist_matrix=(np.zeros((56,600,3)))\n",
    "    dist_matrix=np.array(dist_matrix)\n",
    "\n",
    "    deep_learning(dist_matrix,score)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
