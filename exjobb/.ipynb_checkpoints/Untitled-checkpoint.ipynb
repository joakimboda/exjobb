{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import Bio\n",
    "from Bio.PDB import *\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#This is for removing Bio.python warnings\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "\n",
    "#import pandas as pd #pandas är en python modul for att hantera s.k DataFrames.\n",
    " \n",
    "        \n",
    "def find_structure_params(structure):\n",
    "    \n",
    "    #structure_data.append([Chain_id,Seg_id, residue_name, atom_name, atom_coord_vector])\n",
    "    structure_data={}\n",
    "    res_key = ''\n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            \n",
    "            #for atom in structure.get_atoms():  If I want all atoms in a structure, depends if I want the residue\n",
    "            for residue in chain:\n",
    "                if residue.get_full_id()[3][0]==' ':  #If I want to remove HOH etc (hetero-atoms) use this!\n",
    "                    for atom in residue:\n",
    "                        key = chain.get_id() + str(atom.serial_number)\n",
    "                        structure_data[key]=([chain.get_id(),residue.get_resname(),atom.get_name(),atom.get_vector()])\n",
    "                        \n",
    "                        #Giving the C-terminal O its own name for when making the atom layers\n",
    "                        if atom.get_name()=='OXT':\n",
    "                            structure_data[res_key][2]=structure_data[res_key][2]+'Cterm'\n",
    "                        res_key = key\n",
    "   # for i in structure_data:\n",
    "       # if i[0]=='L':\n",
    "     #       print i\n",
    "\n",
    "\n",
    "    return (structure_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_atom_layers(structure_data):\n",
    "    \n",
    "    layer1_check = ['CYS:SG','MET:SD','MSE:SE']\n",
    "    layer2_check = ['ASN:ND2','GLN:NE2'] #Backbone N\n",
    "    layer3_check = ['HIS:ND1','HIS:NE1','TRP:NE1']\n",
    "    layer4_check = ['ARG:NE','ARG:NH1','ARG:NH2','ARG:NH3']\n",
    "    layer5_check = ['LYS:NZ']\n",
    "    layer6_check = ['ASN:OD1','GLN:OE1'] #Backbone O?\n",
    "    layer7_check = ['SER:OG','THR:OG1','TYR:OH']\n",
    "    layer8_check = ['ASP:OD1','ASP:OD2','ASP:OD3','GLU:OE1','GLU:OE2','GLU:OE3']\n",
    "    layer9_check = ['ARG:CZ','ASN:CG','ASP:CG','GLN:CD','GLU:CD'] #Backbone C?\n",
    "    layer10_check = ['HIS:CG','HIS:CD2','HIS:CE1','PHE:CG','PHE:CD1','PHE:CD2','PHE:CD3','PHE:CE1','PHE:CE2','PHE:CE3','PHE:CZ','TRP:CG','TRP:CD1','TRP:CD2','TRP:CD3','TRP:CD3','TRP:CE1','TRP:CE2','TRP:CE3','TRP:CZ1','TRP:CZ2','TRP:CZ3','TRP:CH2','TYR:CG','TYR:CD1','TYR:CD2','TYR:CD3','TYR:CE1','TYR:CE2','TYR:CE3','TYR:CZ']\n",
    "    layer11_check = ['ALA:CB','ARG:CB','ARG:CG','ARG:CD','ASN:CB','ASP:CB','CYS:CB','GLN:CB','GLN:CG','GLU:CB','GLU:CG','HIS:CB','ILE:CB','ILE:CG1','ILE:CG2','ILE:CG3','ILE:CD1','LEU:CB','LEU:CG','LEU:CD1','LEU:CD2','LEU:CD3','LYS:CB','LYS:CG','LYS:CD','LYS:CE','MET:CB','MET:CG','MET:CE','MSE:CB','MSE:CG','MSE:CE','PHE:CB','PRO:CB','PRO:CG','PRO:CD','SER:CB','THR:CB','THR:CG2','TRP:CB','TYR:CB','VAL:CB','VAL:CG1','VAL:CG2','VAL:CG3'] #Backbone CA?\n",
    "    \n",
    "    layers={}\n",
    "    \n",
    "    for key, atom in structure_data.items():\n",
    "        if atom[2] == 'N':\n",
    "            layers.setdefault('2', []).append(atom)\n",
    "        elif atom[2] == 'O':\n",
    "            layers.setdefault('6', []).append(atom)\n",
    "        elif atom[2] == 'C':\n",
    "            layers.setdefault('9', []).append(atom)\n",
    "        elif atom[2] == 'CA':\n",
    "            layers.setdefault('11', []).append(atom)\n",
    "        elif atom[2] == 'OXT':\n",
    "            layers.setdefault('8', []).append(atom)\n",
    "        elif atom[2] == 'OCterm': #C-terminal O\n",
    "            layers.setdefault('8', []).append(atom)\n",
    "        else:\n",
    "            atom_type = atom[1] + ':' + atom[2]\n",
    "            if atom_type in layer1_check:\n",
    "                layers.setdefault('1', []).append(atom)\n",
    "            elif atom_type in layer2_check:\n",
    "                layers.setdefault('2', []).append(atom)\n",
    "            elif atom_type in layer3_check:\n",
    "                layers.setdefault('3', []).append(atom)\n",
    "            elif atom_type in layer4_check:\n",
    "                layers.setdefault('4', []).append(atom)\n",
    "            elif atom_type in layer5_check:\n",
    "                layers.setdefault('5', []).append(atom)\n",
    "            elif atom_type in layer6_check:\n",
    "                layers.setdefault('6', []).append(atom)\n",
    "            elif atom_type in layer7_check:\n",
    "                layers.setdefault('7', []).append(atom)\n",
    "            elif atom_type in layer8_check:\n",
    "                layers.setdefault('8', []).append(atom)\n",
    "            elif atom_type in layer9_check:\n",
    "                layers.setdefault('9', []).append(atom)\n",
    "            elif atom_type in layer10_check:\n",
    "                layers.setdefault('10', []).append(atom)\n",
    "            elif atom_type in layer11_check:\n",
    "                layers.setdefault('11', []).append(atom)\n",
    "            else:\n",
    "                d=1# print str(key) + str(atom[1:3]) + ' Has not been assigned to any layer' #layers.setdefault('12', []).append(atom)\n",
    "    \n",
    "    #This is to check if anything is not sorted into a layer            \n",
    "    #for key,atom in layers.items():\n",
    "        #if key=='12':\n",
    "           # for x in atom:\n",
    "             #   print x\n",
    "\n",
    "    return(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_midpoint(structure_data):\n",
    "    \n",
    "    allvectors = Vector([0,0,0])\n",
    "\t\n",
    "    i=0     \n",
    "    for key, atom in structure_data.items():\n",
    "        allvectors=allvectors+atom[3]\n",
    "        i=i+1\n",
    "    midpoint=Vector([allvectors[0]/i,allvectors[1]/i,allvectors[2]/i])\n",
    "    return(midpoint)    \n",
    "\n",
    "\n",
    "\n",
    "def normalize_in_origo(midpoint,structure_data):\n",
    "\n",
    "    for key,atom in structure_data.items():\n",
    "        newvector = atom[3] - midpoint\n",
    "        atom_new=[atom[0],atom[1],atom[2],newvector]\n",
    "        structure_data[key]=atom_new\n",
    "\n",
    "    return (structure_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_density_maps(layers,density_maps,counter):\n",
    "    \n",
    "        for g in range(1, 12):\n",
    "            density_maps[counter].append(np.zeros((120,120,120)))\n",
    "            #density_maps[counter]=np.append(np.zeros((120,120,120)))\n",
    "        density_maps[counter]=np.array(density_maps[counter])    \n",
    "        for key,atom in layers.items():\n",
    "            for pos in atom:\n",
    "                x=int(np.around(pos[3][0], decimals=0))+60\n",
    "                y=int(np.around(pos[3][1], decimals=0))+60\n",
    "                z=int(np.around(pos[3][2], decimals=0))+60\n",
    "                \n",
    "                for xx in range(-2,3):\n",
    "                    for yy in range(-2,3):\n",
    "                        for zz in range(-2,3):\n",
    "                            r=float(max(abs(xx),abs(yy),abs(zz)))\n",
    "                            density=math.exp(-((r**2)/2))\n",
    "                            density_maps[counter][(int(key)-1)][x+xx][y+yy][z+zz]=(density_maps[counter][(int(key)-1)][x+xx][y+yy][z+zz]+density)\n",
    "\n",
    "        #This is only for plotting the data in python, otherwise a numpy array is made over all layers\n",
    "        x_values=[]\n",
    "        y_values=[]\n",
    "        z_values=[]\n",
    "        density_values = []\n",
    "        \n",
    "        for x in range(0,120):\n",
    "            for y in range(0,120):\n",
    "                for z in range(0,120):\n",
    "                    if density_maps[counter][1][x][y][z]>0.0:\n",
    "                        x_values.append(x)\n",
    "                        y_values.append(y)\n",
    "                        z_values.append(z)\n",
    "                        density_values.append(density_maps[counter][1][x][y][z])\n",
    "        \n",
    "        return (density_maps,x_values,y_values,z_values,density_values)               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_learning(protein_maps,protein_targets):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.convolutional import Conv3D\n",
    "    from keras.layers import Conv3D, MaxPooling3D,Activation,Reshape\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "    from keras.optimizers import Adam\n",
    "    \n",
    "    import keras.backend as K #For compile\n",
    "    \n",
    "    print('Start training')\n",
    "    seq = Sequential()\n",
    "\n",
    "    #seq.add(Conv3D(11, 3, 3, 3, activation='relu', \n",
    "                            #border_mode='valid', name='conv1',\n",
    "                            #subsample=(1, 1, 1),\n",
    "\t\t\t    #dim_ordering='th', \n",
    "                            #input_shape=(11,120, 120, 120)))\n",
    "\n",
    "\n",
    "    seq.add(Conv3D(filters=11, kernel_size=(3), strides=(1), activation='relu',padding='same', data_format='channels_first', input_shape=(20)))\n",
    "\n",
    "    seq.add(MaxPooling3D(pool_size=(3,3,3),strides=(2,2,2),data_format='channels_first'))\n",
    "\n",
    "    \n",
    "   # seq.add(Conv3D(filters=16, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "   # seq.add(BatchNormalization())\n",
    "    \n",
    "   # seq.add(Activation('relu'))\n",
    "\n",
    "   # seq.add(MaxPooling3D(pool_size=(3,3,3),strides=(2,2,2)))\n",
    "\n",
    "    \n",
    "    #seq.add(Conv3D(filters=32, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Conv3D(filters=32, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "   \n",
    "    #seq.add(MaxPooling3D(pool_size=(3,3,3),strides=(2,2,2)))\n",
    "\n",
    "\n",
    "    #seq.add(Conv3D(filters=64, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Conv3D(filters=128, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Conv3D(filters=256, kernel_size=(3,3,3), strides=(1,1,1),padding='same', data_format='channels_first'))\n",
    "\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(MaxPooling3D(pool_size=(3,3,3),strides=(2,2,2)))\n",
    "\n",
    "    \n",
    "    #seq.add(Reshape((-1,)))\n",
    "\n",
    "    #seq.add(Activation('linear'))\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Activation('linear'))\n",
    "\n",
    "    #seq.add(Activation('relu'))\n",
    "\n",
    "    #seq.add(Activation('linear'))\n",
    "\n",
    "\n",
    "    \n",
    "    def mean_pred(y_true, y_pred):\n",
    "        return K.mean(y_pred)\n",
    "    \n",
    "\n",
    "\n",
    "    adam = Adam(lr=0.0003, decay=0.01)\n",
    "    seq.compile(loss='mean_squared_error',\n",
    "\t      optimizer=adam,\n",
    "              metrics=['accuracy', mean_pred])\n",
    "\n",
    "\t\n",
    "    seq.fit(protein_maps,protein_targets,\n",
    "          epochs=20,\n",
    "          batch_size=9)\n",
    "    \n",
    "    print('Training done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save or load-r\n",
      "-Loading files...\n",
      "[ 0.5768803   0.19176816  0.90155747  0.19220927  0.99130456  0.58302908\n",
      "  0.42018486  0.54933533  0.06802952  0.91029034  0.30144132  0.18808182\n",
      "  0.5186127   0.96076151  0.65711877  0.81588673  0.3903431   0.71665578\n",
      "  0.87003353  0.5555125 ]\n",
      "(20,)\n",
      "(20, 11, 120, 120, 120)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.float64'>\n",
      "Start training\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-3c1579c7dcc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-340-3c1579c7dcc4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mdeep_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_maps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotein_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-339-774edbd1af9e>\u001b[0m in \u001b[0;36mdeep_learning\u001b[0;34m(protein_maps, protein_targets)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m                  \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                  **kwargs):\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joakim/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    \n",
    "    #Dir path\n",
    "    args = sys.argv[1:]\n",
    "\n",
    "    \n",
    "    files='/home/joakim/Downloads/models/' #str(args[0])\n",
    "    \n",
    "    while 'true':\n",
    "        input1=raw_input(\"Save or load\")\n",
    "        if input1.lower()=='-r':\n",
    "            args='-r'\n",
    "            break\n",
    "        elif input1.lower()=='-s':\n",
    "            args='-s'\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "\n",
    "\n",
    "    if not '-r' in args:\n",
    "        df=pd.read_excel('/home/joakim/Downloads/cross_val_sets.xls')\n",
    "        targets={}\n",
    "        for i,row in df.iterrows():\n",
    "             targets.setdefault(i, []).append(row['Targets'].split())\n",
    "\n",
    "        datasets={}\n",
    "        for dir in os.listdir('/home/joakim/Downloads/CnM-dataset/MOAL_Benchmark/'):\n",
    "            for key,target in targets.items():\n",
    "                if dir in str(target):\n",
    "                    datasets.setdefault(key, []).append(dir)\n",
    "\n",
    "\n",
    "        df=pd.read_excel('/home/joakim/Downloads/cross_val_sets.xls')\n",
    "        targets={}\n",
    "        for i,row in df.iterrows():\n",
    "             targets.setdefault(i, []).append(row['Targets'].split())\n",
    "\n",
    "        dir_home='/home/joakim/Downloads/CnM-dataset/MOAL_Benchmark_test/'\n",
    "        datasets={}\n",
    "\n",
    "        for dir in os.listdir(dir_home):\n",
    "            for key,target in targets.items():\n",
    "                if dir in str(target):\n",
    "                    datasets.setdefault(key, []).append(dir)\n",
    "\n",
    "        protein_maps=np.empty([1, 11, 120, 120, 120])\n",
    "        protein_targets=np.empty([1, 11, 120, 120, 120])\n",
    "        for key,protein_list in datasets.items():\n",
    "\n",
    "            for prot_counter,protein in enumerate(protein_list):\n",
    "\n",
    "\n",
    "                pdb_list=[]\n",
    "                for file in os.listdir(dir_home + protein):\n",
    "                    if file.endswith(\".pdb\"):\n",
    "                        pdb_list.append(dir_home + protein+'/'+file)\n",
    "\n",
    "                density_target=[]  \n",
    "                density_maps=[]\n",
    "                counterr=0\n",
    "                countertargets=0\n",
    "           # if not '-r' in args:\n",
    "                for counter, filename_pdb in enumerate(pdb_list):\n",
    "                    print(filename_pdb)\n",
    "                    percent= np.around((np.float(counter+1) / len(pdb_list)*100), decimals=3)\n",
    "                    print(str((counter+1)) +'/'+ str(len(pdb_list)) + ', ' + str(percent)+'%')\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "                    #filename_pdb = '/home/joakim/Downloads/5eh6.pdb'#'/home/joakim/Downloads/2HIY_A.pdb' #'/home/joakim/Downloads/D1A2K-a0a-merged.pdb'\n",
    "                    try: \n",
    "                        PDBobj = PDBParser()\n",
    "                        structure = PDBobj.get_structure(filename_pdb, filename_pdb)\n",
    "\n",
    "                    except IOError: \n",
    "                        print('IO Error', filename_pdb)       \n",
    "                        while 'true':\n",
    "                            input1=raw_input(\"Error parsing PDB file! Continue(y/n)...\")\n",
    "                            if input1.lower()=='y':\n",
    "                                break\n",
    "                            elif input1.lower()=='n':\n",
    "                                sys.exit()\n",
    "\n",
    "\n",
    "                    structure_data = find_structure_params(structure)\n",
    "\n",
    "                    midpoint = find_midpoint(structure_data) #Avrundning gör att det blir lite konstigt,!! Kolla upp\n",
    "\n",
    "                    structure_data = normalize_in_origo(midpoint,structure_data)\n",
    "\n",
    "                    layers = make_atom_layers(structure_data)\n",
    "                    \n",
    "                    if 'a0a' in filename_pdb:\n",
    "                        density_target.append([])\n",
    "                        (density_target,x_values,y_values,z_values,density_values) = make_density_maps(layers,density_target,countertargets)\n",
    "                        countertargets=countertargets+1\n",
    "                    else:\n",
    "                    #Create 11 density maps (zeros)\n",
    "                        density_maps.append([])\n",
    "                        #density_target.append([])\n",
    "                        (density_maps,x_values,y_values,z_values,density_values) = make_density_maps(layers,density_maps,counterr)\n",
    "                        #(density_target,x_values,y_values,z_values,density_values) = make_density_maps(layers,density_target,countertargets)\n",
    "                        counterr=counterr+1\n",
    "                       # countertargets=countertargets+1\n",
    "                    \n",
    "           # for x in density_maps:\n",
    "                #protein\n",
    "\n",
    "                density_maps=np.array(density_maps)\n",
    "                density_target=np.array(density_target)\n",
    "\n",
    "                protein_targets=np.concatenate((protein_targets, density_target), axis=0)\n",
    "                protein_maps=np.concatenate((protein_maps, density_maps), axis=0)\n",
    "\n",
    "        protein_targets=protein_targets[1:]\n",
    "        protein_maps=protein_maps[1:]\n",
    "\n",
    "#For saving and loading the array as an compressed npz file\n",
    "    if '-s' in args and '-r' in args:\n",
    "        print('Do not use save(-s) and read(-r) at the same time')\n",
    "        sys.exit()\n",
    "    elif '-s' in args:\n",
    "        print('-Saving files...')\n",
    "        np.savez_compressed('protein_maps', protein_maps)\n",
    "        #np.savez_compressed('protein_test', protein_test)\n",
    "        np.savez_compressed('protein_targets', protein_targets)\n",
    "        print('-Files saved as \"protein_train.npz\",\"protein_test.npz\",\"protein_target.npz\"')\n",
    "\n",
    "    elif '-r' in args:\n",
    "        print('-Loading files...')\n",
    "        protein_maps = np.load('protein_maps.npz')\n",
    "        #protein_test = np.load('protein_test.npz')\n",
    "        protein_targets = np.load('protein_targets.npz')\n",
    "        \n",
    "        for key,array in protein_maps.items():\n",
    "            protein_maps=protein_maps[key]\n",
    "       # for key,array in protein_test.items():\n",
    "           # protein_test=protein_test[key]\n",
    "        for key,array in protein_targets.items():\n",
    "            protein_targets=protein_targets[key]\n",
    "    \n",
    "    \n",
    "    protein_targets=np.random.rand(20)\n",
    "    print protein_targets\n",
    "    \n",
    "    print(protein_targets.shape)\n",
    "    print(protein_maps.shape)\n",
    "    print(type(protein_maps))\n",
    "    print(type(protein_maps[0]))\n",
    "    print(type(protein_maps[0][0]))\n",
    "    print(type(protein_maps[0][0][0]))\n",
    "    print(type(protein_maps[0][0][0][0]))\n",
    "    print(type(protein_maps[0][0][0][0][0]))\n",
    "\t\t\n",
    "    deep_learning(protein_maps,protein_targets)\n",
    "        \n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
