{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio.PDB import *\n",
    "import sys\n",
    "import re\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas\n",
    "import multiprocessing\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "#This is for removing Bio.python warnings\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_alpha_complex(alphaprot,cwd):\n",
    "    \n",
    "    for key,coords in alphaprot.items():\n",
    "        tmpoutfile =open(cwd+'/pts_dir/tmp.csv', 'w')\n",
    "        tmpoutfile.write('x1,x2,x3\\n')\n",
    "        for coord in coords:\n",
    "            tmpoutfile.write(coord+'\\n')\n",
    "        tmpoutfile.close()\n",
    "        os.system('Rscript PH_Alpha.R '+ cwd+'/pts_dir/tmp.csv '+ cwd+'/pts_dir'+'/tmp.out')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_residue_dist(residue1, residue2, outfile, atom1_used, atom2_used, alphaprot) :\n",
    "\n",
    "    for atom1 in residue1:\n",
    "        for atom2 in residue2:\n",
    "            \n",
    "            distance=atom1-atom2    \n",
    "\n",
    "            if distance>20:#If the residues is to far from eachother there is no need to calculate the distance for the rest of the atoms\n",
    "                return(alphaprot)\n",
    "            if distance >12:#Go to the next atom\n",
    "                continue\n",
    "                \n",
    "            if 'H' not in atom1.get_id() and 'H' not in atom2.get_id(): # DUBBELKOLLA ATT DET INTE FINNS H I ANDRA!!!!\n",
    "            #if atom1.get_id() != 'H' and atom2.get_id() != 'H':    \n",
    "                \n",
    "                a1_serial=str(atom1.serial_number)\n",
    "                a2_serial=str(atom1.serial_number)\n",
    "                if a1_serial not in atom1_used:\n",
    "                    atom1_used.append(a1_serial)\n",
    "                    x=str(atom1.get_coord()[0])\n",
    "                    y=str(atom1.get_coord()[1])\n",
    "                    z=str(atom1.get_coord()[2])\n",
    "                    if 'C' in atom1.get_name():# and\n",
    "                        outfile.write('0'+' '+'1'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('C', []).append(x+' '+y+' '+z)\n",
    "                    elif 'O' in atom1.get_name():\n",
    "                        outfile.write('0'+' '+'2'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('O', []).append(x+' '+y+' '+z)\n",
    "                    elif 'N' in atom1.get_name():\n",
    "                        outfile.write('0'+' '+'3'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('N', []).append(x+' '+y+' '+z)\n",
    "                    elif 'S' in atom1.get_name():\n",
    "                        outfile.write('0'+' '+'4'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('S', []).append(x+' '+y+' '+z)\n",
    "                if a2_serial not in atom2_used:\n",
    "                    atom2_used.append(a2_serial)\n",
    "                    x=str(atom2.get_coord()[0])\n",
    "                    y=str(atom2.get_coord()[1])\n",
    "                    z=str(atom2.get_coord()[2])\n",
    "                    if 'C' in atom1.get_name():\n",
    "                        outfile.write('1'+' '+'1'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('C', []).append(x+' '+y+' '+z)\n",
    "                    elif 'O' in atom1.get_name():\n",
    "                        outfile.write('1'+' '+'2'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('O', []).append(x+' '+y+' '+z)\n",
    "                    elif 'N' in atom1.get_name():\n",
    "                        outfile.write('1'+' '+'3'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('N', []).append(x+' '+y+' '+z)\n",
    "                    elif 'S' in atom1.get_name():\n",
    "                        outfile.write('1'+' '+'4'+' '+x+' '+y+' '+z+'\\n')\n",
    "                        alphaprot.setdefault('S', []).append(x+' '+y+' '+z)\n",
    "                \n",
    "    return(alphaprot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_dist_matrix(chain_one, chain_two,outfile,alphaprot) :\n",
    "    \n",
    "    atom1_used=[]\n",
    "    atom2_used=[]\n",
    "    for row, residue_one in enumerate(chain_one) :\n",
    "        for col, residue_two in enumerate(chain_two) :\n",
    "            \n",
    "            alphaprot=calc_residue_dist(residue_one, residue_two, outfile, atom1_used, atom2_used, alphaprot)\n",
    "                                    \n",
    "    return(alphaprot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save or load -s\n",
      "0\n",
      "D1AKJ-a0c-merged.pdb\n",
      "1\n",
      "D1AKJ-a0d-merged.pdb\n",
      "2\n",
      "D1AKJ-a1a-merged.pdb\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    #Dir path\n",
    "    #args = sys.argv[1:]\n",
    "    \n",
    "    pdb_dir= cwd+'/models' #'D:\\Downloads\\CnM-dataset\\models'#'/home/joakim/Downloads/models' #str(args[0]) \n",
    "    \n",
    "    \n",
    "    while 'true':\n",
    "        input1=raw_input(\"Save or load \")\n",
    "        if input1.lower()=='-r':\n",
    "            args='-r'\n",
    "            break\n",
    "        elif input1.lower()=='-s':\n",
    "            args='-s'\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if not '-r' in args:\n",
    "    \n",
    "        pdb_list=[]\n",
    "        for file in os.listdir(pdb_dir):\n",
    "            if file.endswith(\".pdb\"):\n",
    "                pdb_list.append([pdb_dir,file])\n",
    "      \n",
    "        valuefile= cwd+'CnM.featuresNPqDNZ'#'/home/joakim/Downloads/CnM.featuresNPqDNZ'#'D:\\Downloads\\CnM.featuresNPqDNZ'\n",
    "        value_df=pandas.read_csv(valuefile,delim_whitespace=1)\n",
    "\n",
    "        #Just a check to se if the data_set dir exist, in this case it removes it and all the files in it and make a new one\n",
    "        if os.path.exists(cwd + \"/pts_dir\"):\n",
    "            shutil.rmtree(cwd + \"/pts_dir\")\n",
    "            os.makedirs(cwd + \"/pts_dir\")\n",
    "        else:\n",
    "            os.makedirs(cwd + \"/pts_dir\")\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        score=[]\n",
    "        dist_matrix=[]\n",
    "        for counter, filepath_pdb in enumerate(pdb_list):\n",
    "            \n",
    "            working_file=open(cwd + '/pts_dir/working_file.txt', 'a')\n",
    "            working_file.write(pdb_list[counter][1][:-11]+'\\n') #Writes what pdb have been worked on in working_file.txt\n",
    "            working_file.close()\n",
    "            \n",
    "            print(counter)\n",
    "            print(pdb_list[counter][1])\n",
    "            filename_pdb=os.path.join(pdb_list[counter][0],pdb_list[counter][1])\n",
    "\n",
    "            try: \n",
    "                PDBobj = PDBParser()\n",
    "                structure = PDBobj.get_structure(filename_pdb, filename_pdb)\n",
    "                model = structure[0]\n",
    "            except IOError: \n",
    "                print('IO Error', filename_pdb)      \n",
    "                while 'true':\n",
    "                    input1=raw_input(\"Error parsing PDB file! Continue(y/n)...\")\n",
    "                    if input1.lower()=='y':\n",
    "                        continue\n",
    "                    elif input1.lower()=='n':\n",
    "                        sys.exit()\n",
    "\n",
    "           \n",
    "            score.append(value_df.loc[((value_df['#'] == pdb_list[counter][1][:-11]),'CPscore')].values[0])\n",
    "\n",
    "\n",
    "\n",
    "            chain_used=[]\n",
    "            outfile=open(cwd + \"/pts_dir/\"+pdb_list[counter][1][:-11] + '.pts', 'w')\n",
    "            for chain1 in model:\n",
    "                for chain2 in model:\n",
    "                    alphaprot={} #Used to make temp file for alpha complex calculations, its a dict of coord for every atomtype used\n",
    "                    if chain1!=chain2 and chain2 not in chain_used:\n",
    "                        chain_used.append(chain1)\n",
    "                        alphaprot=calc_dist_matrix(chain1, chain2, outfile,alphaprot) #Makes coord files for matlab and returns a dict for alpha complex\n",
    "                        calculate_alpha_complex(alphaprot,cwd) #Calculates alpha complex\n",
    "                        \n",
    "            outfile.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    if '-s' in args and '-r' in args:\n",
    "        print('Do not use save(-s) and read(-r) at the same time')\n",
    "        sys.exit()\n",
    "    elif '-s' in args:\n",
    "        print('-Saving files...')\n",
    "        np.savez_compressed('score', score)\n",
    "        #np.savez_compressed('dist_matrix', dist_matrix)\n",
    "        print('-Files saved as \"dist_matrix.npz\",\"score.npz\"')\n",
    "\n",
    "    elif '-r' in args:\n",
    "        print('-Loading files...')\n",
    "        score = np.load('score.npz')\n",
    "        #dist_matrix = np.load('dist_matrix.npz')\n",
    "        \n",
    "        for key,array in score.items():\n",
    "            score=score[key]\n",
    "        #for key,array in dist_matrix.items():\n",
    "            #dist_matrix=dist_matrix[key]\n",
    "            \n",
    "        print('-Files loaded')\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(score[1])\n",
    "    print(score.shape)\n",
    " \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
